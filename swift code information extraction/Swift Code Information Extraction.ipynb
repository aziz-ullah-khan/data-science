{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Swift Code Analysis Refined Version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "055d9556bd704ce4b284ddbbf8eb6b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab31d41a02ed4e39b13da15fb71d5dd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8bb7a408075842489a5599d34cc7b338",
              "IPY_MODEL_fcdeef4d925e4eebb9d02c3de792fc07"
            ]
          }
        },
        "ab31d41a02ed4e39b13da15fb71d5dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bb7a408075842489a5599d34cc7b338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08c2d0cf02b34068b8da96aa5ac694bb",
            "_dom_classes": [],
            "description": " 84%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 672,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c35adef69f2e4bf1b6ae277d3d9e44cc"
          }
        },
        "fcdeef4d925e4eebb9d02c3de792fc07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8648947a6ec24710973fb047ebbb43be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 672/800 [31:41&lt;06:08,  2.88s/it, Loss: 0.00073]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cf072e7e14c4735929c4e12b3668042"
          }
        },
        "08c2d0cf02b34068b8da96aa5ac694bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c35adef69f2e4bf1b6ae277d3d9e44cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8648947a6ec24710973fb047ebbb43be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cf072e7e14c4735929c4e12b3668042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8989fc0341214eb9933631cd7915e47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01c7500e9e344ba7bbf7dbc2e9f55340",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a3b8f57ad77c4e3b9ae0056c2323bd7c",
              "IPY_MODEL_9890c2f966a4497684e028bb2dadaffd"
            ]
          }
        },
        "01c7500e9e344ba7bbf7dbc2e9f55340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3b8f57ad77c4e3b9ae0056c2323bd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38c14786e0e349e2aaca2a053d6f2869",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db603e256fbe4be0a4a74eadae3b85f7"
          }
        },
        "9890c2f966a4497684e028bb2dadaffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58321b5435024847b0e4a09dbe4679fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00,  3.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f36934e50691429695806ba2d1c11a84"
          }
        },
        "38c14786e0e349e2aaca2a053d6f2869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db603e256fbe4be0a4a74eadae3b85f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58321b5435024847b0e4a09dbe4679fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f36934e50691429695806ba2d1c11a84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHE3T51UuvFh"
      },
      "source": [
        "### Install required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Q0KqW1sxHq"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install seqeval"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smu6_rjdu2Qv"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGA13KSBs3Kg"
      },
      "source": [
        "from transformers import BertTokenizer, BertForTokenClassification, get_scheduler, AdamW\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "from tqdm.auto import tqdm\n",
        "from seqeval.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import datetime as dt\n",
        "import pickle"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-4cKxuZu8Kc"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_kLcn2eu4k9"
      },
      "source": [
        "model_name = 'bert-base-multilingual-cased'  # 'bert-large-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "O2f6t-IZvC5d",
        "outputId": "c0bdfce9-6fd9-41ce-a8a4-6eb71134ce44"
      },
      "source": [
        "raw_data = pd.read_excel('dataset_version_one .xlsx')\n",
        "raw_data.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>indexes</th>\n",
              "      <th>keywords</th>\n",
              "      <th>label</th>\n",
              "      <th>code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13-19, 4-11</td>\n",
              "      <td>String, _field1</td>\n",
              "      <td>variable_type, variable_name</td>\n",
              "      <td>var _field1: String? = nil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13-18, 4-11</td>\n",
              "      <td>Int32, _field2</td>\n",
              "      <td>variable_type, variable_name</td>\n",
              "      <td>var _field2: Int32? = nil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8-26, 8-26, 8-34, 4-6</td>\n",
              "      <td>SDTTopLevelMessage, SDTTopLevelMessage, SDTTop...</td>\n",
              "      <td>object_name, object_name, variable_type, varia...</td>\n",
              "      <td>var _o: SDTTopLevelMessage.OneOf_O?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>29-42, 11-26</td>\n",
              "      <td>_StorageClass, defaultInstance</td>\n",
              "      <td>object_name, variable_name</td>\n",
              "      <td>static let defaultInstance = _StorageClass()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8-12</td>\n",
              "      <td>init</td>\n",
              "      <td>object_name</td>\n",
              "      <td>private init() {}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 indexes  ...                                          code\n",
              "0            13-19, 4-11  ...                    var _field1: String? = nil\n",
              "1            13-18, 4-11  ...                     var _field2: Int32? = nil\n",
              "2  8-26, 8-26, 8-34, 4-6  ...           var _o: SDTTopLevelMessage.OneOf_O?\n",
              "3           29-42, 11-26  ...  static let defaultInstance = _StorageClass()\n",
              "4                   8-12  ...                             private init() {}\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-S_qE1cmqym"
      },
      "source": [
        "def sentences_format(indexes, label, code, tokenizer):\n",
        "\n",
        "    tokens = tokenizer(code, is_split_into_words= True, add_special_tokens=False)\n",
        "    sentence = tokenizer.convert_ids_to_tokens(tokens.input_ids)\n",
        "    tag_labels = [None] * len(sentence)\n",
        "    label = label\n",
        "    for index, lbl in zip(indexes.split(','), label.split(',')):\n",
        "        idx = index.split('-')\n",
        "        s_tokens = code[int(idx[0]):int(idx[1])]\n",
        "        t_tokens = tokenizer(s_tokens, is_split_into_words= True, add_special_tokens=False)\n",
        "        tag_tokens = tokenizer.convert_ids_to_tokens(t_tokens.input_ids)\n",
        "       #print(f'{lbl.strip()} {code[int(idx[0]):int(idx[1])]}')    \n",
        "        if len(tag_tokens)>1:\n",
        "            local_index = []\n",
        "            for itr, tag in enumerate(tag_tokens):\n",
        "                for sitr, s_tag in enumerate(sentence):\n",
        "                    if tag == s_tag:\n",
        "                        if itr+1 < len(tag_tokens) and sitr+1 < len(sentence):\n",
        "                            if tag_tokens[itr+1] == sentence[sitr+1]:\n",
        "                                local_index.append(sitr)\n",
        "                                local_index.append(sitr+1)\n",
        "\n",
        "            for i in range(len(local_index)):\n",
        "                if i == 0:\n",
        "                    tag_labels[local_index[i]]= f'B-{lbl.strip()}'\n",
        "                else:\n",
        "                    tag_labels[local_index[i]] = f'I-{lbl.strip()}'\n",
        "\n",
        "        else:\n",
        "            t_idx = sentence.index(tag_tokens[0])\n",
        "            tag_labels[t_idx] = f'B-{lbl.strip()}'\n",
        "        pass\n",
        "    return sentence, tag_labels"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyhsKYI2o7O3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "389915bd-474a-4bac-f66a-c101ce546e06"
      },
      "source": [
        "all_tokens = []\n",
        "all_tags = []\n",
        "sent_id = []\n",
        "sent_count = 0\n",
        "for index, row in raw_data.iterrows():\n",
        "    sentence_tokens, tag_labels = sentences_format(row['indexes'], row['label'], row['code'], tokenizer)\n",
        "    sent_count += 1\n",
        "    for token in sentence_tokens:\n",
        "      all_tokens.append(token)\n",
        "    for lbl in tag_labels:\n",
        "      if lbl == None:\n",
        "        all_tags.append('O')\n",
        "      else:\n",
        "        all_tags.append(lbl)\n",
        "      sent_id.append(sent_count)\n",
        "\n",
        "    if index % 1000 == 0:\n",
        "      print(f'Processed Rows {index}')\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed Rows 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2cu2iQO4aZz"
      },
      "source": [
        "data_tuples = list(zip(sent_id,all_tokens, all_tags))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2bMvPXw2i9v"
      },
      "source": [
        "token_data = pd.DataFrame(data_tuples, columns =['Sentence Id', 'Token', 'Tag'] )\n",
        "token_data.to_csv('processed_data_.csv')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH7cAu3BypkV"
      },
      "source": [
        "### Loading Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRDjAePAvqGS"
      },
      "source": [
        "dataset = pd.read_csv('processed_data_.csv')\n",
        "dataset.head()\n",
        "dataset = dataset\n",
        "agg_func = lambda s: [(w, t) for w, t in zip(s[\"Token\"].values.tolist(),\n",
        "                                             s[\"Tag\"].values.tolist())]\n",
        "processed_sentences = dataset.groupby(\"Sentence Id\").apply(agg_func).tolist()\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glTrjMow1X-L"
      },
      "source": [
        "### Data processing (formating Data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_acqlbBCWNM_",
        "outputId": "9e86ea3c-eabb-40a2-e0b5-fa9c65607b64"
      },
      "source": [
        "tags_vals = dataset['Tag'].unique().tolist()\n",
        "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "sentences = [' '.join([str(s[0]) for s in sent]) for sent in processed_sentences]\n",
        "labels = [[s[1] for s in sent] for sent in processed_sentences]\n",
        "labels = [[tag2idx.get(l) for l in lab] for lab in labels]\n",
        "\n",
        "# TO DO: Train, Test Split...\n",
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_percent = 0.8\n",
        "train_size = int(train_percent*len(sentences))\n",
        "# train_dataset=df.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
        "# test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_sentences = sentences[0:train_size]\n",
        "train_labels = labels[0:train_size]\n",
        "\n",
        "test_sentences = sentences[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(len(sentences)))\n",
        "print(\"TRAIN Dataset: {}\".format(len(train_sentences)))\n",
        "print(\"TEST Dataset: {}\".format(len(test_sentences)))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: 10\n",
            "TRAIN Dataset: 8\n",
            "TEST Dataset: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdqhHeAqcLnO"
      },
      "source": [
        "def calc_max_len_in_sentences(sentences):\n",
        "    #Confirm maximum word count\n",
        "    max_len = []\n",
        "    #Sentence by sentence processing\n",
        "    for sent in sentences:\n",
        "        # Tokenization\n",
        "        token_words = tokenizer.tokenize(sent)\n",
        "        # Get the number of sentences and store them in the list.\n",
        "        max_len.append(len(token_words))\n",
        "    max_length=max(max_len, default = 0)+2\n",
        "    if max_length>512:\n",
        "        return 512 #BERT allows 512 words\n",
        "    else:\n",
        "        return max_length # Maximum number of words plus +2 of Special token ([CLS], [SEP])\n",
        "\n",
        "def convert_sentences_for_bert(sentences, max_length):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    #1 Sentence by sentence processing\n",
        "    for sent in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      \n",
        "                            add_special_tokens = True, # Add Special Token\n",
        "                            max_length = max_length,   # Fixed sentence length (Padding/Transcatinating)\n",
        "                            padding='max_length',      #Fill with PADDING\n",
        "                            return_attention_mask = True,   # Create Attention Masks\n",
        "                            return_tensors = 'pt',     # return with Pytorch tensors\n",
        "                            truncation=True, \n",
        "                            return_token_type_ids=True\n",
        "                    )\n",
        "\n",
        "       # Get word ID\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # Attention mask acquisition\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "   # Combine the listed tesor longitudinally (dim=0)\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGNjeUeNfpwH"
      },
      "source": [
        "def process_labels(labels, tag2idx, max_length):\n",
        "  processed_labels = []\n",
        "  for indx in range(len(labels)):\n",
        "    label = labels[indx]\n",
        "    label.extend([tag2idx['O']] * max_length)\n",
        "    processed_labels.append(label[:max_length])\n",
        "  return processed_labels"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EIDaEZxhhpD"
      },
      "source": [
        "#train_input_ids.size(), train_attention_masks.size(), tensor_labels.size()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkSjII6mb9TO"
      },
      "source": [
        "# get max length from the training sentences\n",
        "max_length = max(calc_max_len_in_sentences(train_sentences), calc_max_len_in_sentences(test_sentences))\n",
        "\n",
        "# Conversion to BERT format\n",
        "train_input_ids,  train_attention_masks = convert_sentences_for_bert(train_sentences, max_length)\n",
        "test_input_ids, test_attention_masks = convert_sentences_for_bert(test_sentences, max_length)\n",
        "\n",
        "# train dataset\n",
        "train_processed_labels = process_labels(train_labels, tag2idx, max_length)\n",
        "train_tensor_labels = torch.Tensor(train_processed_labels)\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_tensor_labels)\n",
        "\n",
        "# test dataset\n",
        "test_processed_labels = process_labels(test_labels, tag2idx, max_length)\n",
        "test_tensor_labels = torch.Tensor(test_processed_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_tensor_labels)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWkoBIsR_4is"
      },
      "source": [
        "num_labels = len(tags_vals)\n",
        "model = BertForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "# device selection GPU/CPU, prefer GPU \n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YObJS3w_aJV"
      },
      "source": [
        "# hyper parameters\n",
        "batch_size = 1\n",
        "num_epochs = 100\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    random.seed(worker_id)\n",
        "\n",
        "# train data loder with specific batches along with shuffling\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler =  SequentialSampler(train_dataset),\n",
        "            #shuffle = True,\n",
        "            batch_size = batch_size,\n",
        "            worker_init_fn=worker_init_fn\n",
        "        )\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,  \n",
        "            sampler =  SequentialSampler(test_dataset),\n",
        "            #shuffle = True,\n",
        "            batch_size = batch_size,\n",
        "            worker_init_fn=worker_init_fn\n",
        "        )\n",
        "num_testing_steps =  len(test_dataloader)\n",
        "\n",
        "# learning rate scheduler\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwIhf-68shrQ"
      },
      "source": [
        "# save model\n",
        "def save_model(model):\n",
        "  datetime=str(dt.datetime.now()).split(\".\")[0].replace(\":\",\"\").replace(\" \",\"\").replace(\"-\",\"\")\n",
        "  # location with file name of model \n",
        "  model_file = 'model_%s.pickle'%datetime\n",
        "  with open(model_file, mode='wb') as bertf:\n",
        "    pickle.dump(model, bertf)\n",
        "    print(\"Model saved as \" + model_file)\n",
        "\n",
        "# load model\n",
        "def load_model(model_file):\n",
        "  with open(model_file, mode='rb') as bertf:\n",
        "    model= pickle.load(bertf)\n",
        "    print(\"Model loaded from \" + model_file)\n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "055d9556bd704ce4b284ddbbf8eb6b19",
            "ab31d41a02ed4e39b13da15fb71d5dd6",
            "8bb7a408075842489a5599d34cc7b338",
            "fcdeef4d925e4eebb9d02c3de792fc07",
            "08c2d0cf02b34068b8da96aa5ac694bb",
            "c35adef69f2e4bf1b6ae277d3d9e44cc",
            "8648947a6ec24710973fb047ebbb43be",
            "7cf072e7e14c4735929c4e12b3668042"
          ]
        },
        "id": "wj-Esy6KBH-T",
        "outputId": "f1d851e0-16b9-49ef-a3d7-ee6fcbda0de8"
      },
      "source": [
        "# progress bar (tqdm)\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for batch in train_dataloader:\n",
        "        b_input_ids = batch[0].to(device, dtype=torch.long)\n",
        "        b_input_mask = batch[1].to(device, dtype=torch.long)\n",
        "        b_labels = batch[2].to(device, dtype=torch.long)\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix_str(f'Loss: {loss.item():.5f}')\n",
        "    if epoch % 10 == 0:\n",
        "      save_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "055d9556bd704ce4b284ddbbf8eb6b19",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=800.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved as model_20210712160750.pickle\n",
            "Model saved as model_20210712161136.pickle\n",
            "Model saved as model_20210712161519.pickle\n",
            "Model saved as model_20210712161903.pickle\n",
            "Model saved as model_20210712162250.pickle\n",
            "Model saved as model_20210712162634.pickle\n",
            "Model saved as model_20210712163016.pickle\n",
            "Model saved as model_20210712163407.pickle\n",
            "Model saved as model_20210712163759.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5XWzdWV1Atw"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    flat_preds = np.argmax(preds, axis=2).flatten()\n",
        "    flat_labels = labels.flatten()\n",
        "    return np.sum(flat_preds == flat_labels)/len(flat_labels)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfbkapv4kfYL"
      },
      "source": [
        "def valid(model, testing_loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0; eval_accuracy = 0\n",
        "    n_correct = 0; n_wrong = 0; total = 0\n",
        "    predictions , true_labels = [], []\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    progress_bar = tqdm(range(num_testing_steps))\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "          b_input_ids = batch[0].to(device, dtype=torch.long)\n",
        "          b_input_mask = batch[1].to(device, dtype=torch.long)\n",
        "          b_labels = batch[2].to(device, dtype=torch.long)\n",
        "          outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "          loss = outputs.loss\n",
        "          logits = outputs.logits\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "          predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "          true_labels.append(label_ids)\n",
        "          accuracy = flat_accuracy(logits, label_ids)\n",
        "          eval_loss += loss.mean().item()\n",
        "          eval_accuracy += accuracy\n",
        "          nb_eval_examples += b_input_ids.size(0)\n",
        "          nb_eval_steps += 1\n",
        "          progress_bar.update(1)\n",
        "        eval_loss = eval_loss/nb_eval_steps\n",
        "        print(\"Validation loss: {}\".format(eval_loss))\n",
        "        print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "        pred_tags = [[tags_vals[p_i]] for p in predictions for p_i in p]\n",
        "        #print(pred_tags)\n",
        "        valid_tags = [[tags_vals[l_ii]] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "        #print(valid_tags)\n",
        "        print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp2p6JpWniXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "8989fc0341214eb9933631cd7915e47c",
            "01c7500e9e344ba7bbf7dbc2e9f55340",
            "a3b8f57ad77c4e3b9ae0056c2323bd7c",
            "9890c2f966a4497684e028bb2dadaffd",
            "38c14786e0e349e2aaca2a053d6f2869",
            "db603e256fbe4be0a4a74eadae3b85f7",
            "58321b5435024847b0e4a09dbe4679fe",
            "f36934e50691429695806ba2d1c11a84"
          ]
        },
        "outputId": "c9e8be3f-364f-4b1f-ba51-39acd4c648d6"
      },
      "source": [
        "# To get the results on the validation set. This data is not seen by the model\n",
        "valid(model, test_dataloader)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8989fc0341214eb9933631cd7915e47c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5999726429581642\n",
            "Validation Accuracy: 0.9673913043478262\n",
            "F1-Score: 0.6666666666666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZHAazLLCP_-"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kye5JRbQCSqm"
      },
      "source": [
        "def predictions(model, sentence, tokenizer):\n",
        "  pt_sentence = tokenizer(sentence, \n",
        "                          add_special_tokens = True, # Add Special Token\n",
        "                          return_attention_mask = True,   # Create Attention Masks\n",
        "                          return_tensors = 'pt',     # return with Pytorch tensors\n",
        "                          return_token_type_ids=True)\n",
        "  output = model(**pt_sentence.to(device))\n",
        "  loss = output.loss\n",
        "  logits = output.logits\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions = [list(p) for p in np.argmax(logits, axis=2)]\n",
        "  pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "  sentence = tokenizer.convert_ids_to_tokens(pt_sentence.input_ids[0])\n",
        "  return sentence, pred_tags"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tooGJdPQGK1O",
        "outputId": "5729e55e-81f7-4806-b4fb-adab442bcd0c"
      },
      "source": [
        "sentence = 'private init() {}'\n",
        "predictions(model, sentence, tokenizer)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['[CLS]', 'private', 'init', '(', ')', '{', '}', '[SEP]'],\n",
              " ['O', 'B-object_name', 'O', 'O', 'O', 'O', 'O', 'O'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}