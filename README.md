[![author](https://img.shields.io/badge/author-AzizUllahKhan-brightgreen)](https://www.linkedin.com/in/aziz-ullah-khan/) [![](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/) [![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/aziz-ullah-khan/data-science)

<p align="center">
  <img src="https://i.imgur.com/8gqbbxf.png" width = 100%>
</p>

# Aziz Ullah Khan

[Linkedin](https://www.linkedin.com/in/aziz-ullah-khan/) 


## Projects:

Here in this repo you can find notebooks of my data science and machine learning projects.

* **[Paper Summarization](https://github.com/aziz-ullah-khan/data-science/blob/main/paper%20summarization/Paper_Summarization.ipynb):**
This project demonstrates the use of the Bidirectional and Auto-Regressive Transformer (BART) model provided by the Huggingface Transformers library to generate summaries for academic papers in the arXiv Summarization Dataset. By the end of this project, you will have a better understanding of how to use BART to generate summaries for academic papers, and how to evaluate the quality of the generated summaries.

* **[Cartoon Classification](https://github.com/aziz-ullah-khan/data-science/blob/main/cartoon%20classification/Cartoon_Classification.ipynb):**
This project, CARTOON CLASSIFICATION, uses deep learning to identify characters from the TV show "The Simpsons." The ResNet18 algorithm is utilized to train a model on the Kaggle Simpsons Characters Data, with the aim of providing an intuitive and hands-on approach to image classification using deep learning.

* **[Movie Recommendation](https://github.com/aziz-ullah-khan/data-science/blob/main/movie%20recommendation/Movie_Recommendation.ipynb):**
In this project, I use the Movielens dataset and Microsoft Recommenders library to build a movie recommendation system using SAR algorithm. The system is based on user's past movie preferences and can suggest movies to them. The project aims to provide accurate recommendations for both popular and niche items.

* **[Forecasting of COVID](https://github.com/aziz-ullah-khan/data-science/blob/main/forecasting%20of%20Covid/Forecasting_of_COVID.ipynb):**
In this project, I used time-series forecasting and the Meta AI Prophet library to predict the spread of COVID-19 across countries using the Kaggle COVID-19 dataset. I explored and preprocessed the data, built baseline and Prophet models, and evaluated their performance using various metrics. My goal was to provide insights to inform public health policies and interventions in the fight against COVID-19.

* **[Hate Speech Detection Using Transformer](https://github.com/aziz-ullah-khan/data-science/blob/main/hate%20speech%20detection/Hate_Speech_Detection.ipynb):**
In this project, I implemented a hate speech detection model using the DeBERTa algorithm and the Huggingface Transformers library. The model is capable of classifying tweets into one of three categories: hate speech, offensive language, or neutral. I used the Kaggle Hate Speech and Offensive Language Dataset to train and test the model.

* **[Swift Code Information Extractor Using Transformer NER](https://github.com/aziz-ullah-khan/data-science/tree/main/swift%20code%20information%20extraction):**
This project is like a prototype for understanding Swift code by a layman with a native understandable language. The trained model detect the variable type, variable name, object type, object name etc in Swift code. 

* **[Firefox Bugs Classification Using Classical Machine Learning and BERT](https://github.com/aziz-ullah-khan/data-science/tree/main/Firefox%20Bugs%20Classification):**
For the purpose of bugs reports classification, information gathered from the users as feedback or captured from reporting the bugs to the developers, here in this research a tool is developed which are classifying the bugs into their respective bug type with the subsequent classification of the bug reports into their respective components as well. Machine learning techniques such as BERT are proved quite performing in this study for the classification of bugs. It also showed that the bug reports with the help of machine learning can quickly fixed the bugs by identifying the bug in no time and user experience is also promised. Moreover, the proposed model can be further enhanced in different areas.

* **[Quora Question Pairs](https://github.com/aziz-ullah-khan/data-science/tree/main/quora%20question%20pairs):**
Sentences or questions similarities is utmost important in many applications and machine learning approaches have applied to solve this problem by many researchers. Questions similarities is very hot topic these days and many researchers are approaching the problem to solve with a reasonable accuracy. 
In this project, we deep dived with different algorithms/experiments to find the optimal solution to the problem along with the comparison of multiple models. The dataset used for this project is obtained from the Kaggle competition with the name â€œQuora Question Pairsâ€ and is available openly on the website Kaggle.com. In our approach we implemented many classical models like logistic regressions, decision tree. Subsequently we configured BERT transformers with different model type.

* **[Entities Identification in Healthcare Data](https://github.com/aziz-ullah-khan/data-science/tree/main/entities%20identification%20in%20healthcare%20data):**
To derive Name Entity Recognition (NER) on Medical data set so that we can classify the given word as of type Disease, Treatment or Others

* **[Chatbot](https://github.com/aziz-ullah-khan/data-science/tree/main/chatbot):**
Chatbot - Specific for Japanese but can be used for any language with slight tunning!

* **[Microsoft Research Sentence Completion](https://github.com/aziz-ullah-khan/data-science/tree/main/microsoft%20research%20sentence%20completion):**
Sentence completion is a challenging task and is extremely time consuming, which is the challenge of today. Many researchers worked on the autocompletion of the sentence but the complexity arise with the high volume of textual data processing. N-grams along with word2vec and with the combination of wordnet play a key role in the solving the problem by allowing the words to vectorize with the help of word2vec and the distances between the words can be found for similarity. Wordnet which is a lexical database and having semantic relationship between words in over twenty hundred languages and is the part of Natural Language Toolkit corpus. In this study n-grams (uni-gram, bi-gram, tri-gram) are implemented separately and also along with wordnet with word2vec. The dataset used in this study is the Microsoft research sentence completion challenge. The models are first trained with the training textual data and performance is evaluated on the multiple-choice question with five options. The evaluation metrics shown for this study are accuracy, precession, recall, f-1 score respectively. In this novel approach satisfactory results are generated.


---



> Made with ðŸ’– by Aziz Ullah Khan

